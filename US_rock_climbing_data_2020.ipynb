{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06c948a-991b-4d42-8edc-5d7fb30ff67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we want to set the stage and import all required packages as well as the data to perform the analysis.\n",
    "# The data is imported efficiently, loading all data sets in a dictonary where each key (geography)\n",
    "# holds a list of dataframes with all route information within that geography split by state.\n",
    "# Simultaneously the names of each geography gets extracted from the folder names and the names of each state\n",
    "# from the file names.\n",
    "\n",
    "# Load the required packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Collect folder paths of the data\n",
    "all_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-usa-routes-aug-2020\"\n",
    "ca_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-ca\"\n",
    "midwest_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-midwest\"\n",
    "northeast_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-northeast\"\n",
    "southeast_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-southeast\"\n",
    "westcoast_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-westcoast\"\n",
    "m1_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-mountains1\"\n",
    "m2_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-mountain2\"\n",
    "ms2_dir = \"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-routes-mountains2\"\n",
    "\n",
    "# Extract and save the data found in all_dir that holds all route information of the USA from 2020 and save it to all.\n",
    "all = pd.read_json(\"G:/My Drive/Trainings/Python/Trainings_file/climbing project/openbeta-usa-routes-aug-2020/openbeta-usa-routes-aug-2020.jsonlines\", lines= True)\n",
    "\n",
    "\n",
    "# Create a list of all folder path strings, excluding all_dir\n",
    "folder_paths = [ca_dir, midwest_dir, northeast_dir, southeast_dir, westcoast_dir, m1_dir, m2_dir, ms2_dir]\n",
    "\n",
    "# Extract the other geographies:\n",
    "\n",
    "geographies_data = {}  # Initialize an empty dictionary to store the resulting list of dataframes for each geography\n",
    "geographies_states = {} # Initialize an empty dictionary to store the state name strings in lists for each geography\n",
    "\n",
    "# Here we fill the dictinary geography with a list of dataframes for each geograpy. Each dataframe corresponds to a US state:\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    file_list = glob.glob(folder_path + '/*.jsonlines')  # Get a list of all JSON files in the folder\n",
    "    file_list.sort() # Sort the list aphabetically, since glob does not do it\n",
    "\n",
    "    # Extract the state names from the file names in each folder.\n",
    "    file_list_trunc = [] # Initialize empty list\n",
    "    for file in file_list : # For each file in the file_list truncate the string to only keep the state names\n",
    "        file_trunc = file.split('-routes.jsonline', 1)[0]\n",
    "        file_trunc = file_trunc.split('\\\\', 1)[-1]\n",
    "        file_list_trunc.append(file_trunc) # Append the state name to the list of statenames\n",
    "\n",
    "    folder_data_frames = []  # List to store the dataframes for each geography\n",
    "\n",
    "    for file_name in file_list:\n",
    "        data_frame = pd.read_json(file_name, lines = True)\n",
    "        folder_data_frames.append(data_frame)\n",
    "\n",
    "        folder_name = os.path.basename(folder_path) # Extract the folder name\n",
    "        # Strip the first part of the folder name, only keeping the last element of the split.\n",
    "        folder_name = folder_name.split('routes-', 1)[-1] \n",
    "        \n",
    "    # Add the list of DataFrames and state names to the dictionary with the folder name as the key.\n",
    "    # The names need to be unique for later variable extraction, so we add _data or _state to the string.\n",
    "    \n",
    "    geographies_data[folder_name + \"_data\"] = folder_data_frames\n",
    "    geographies_states[folder_name + \"_state\"] = file_list_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d99a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ca_data', 'midwest_data', 'northeast_data', 'southeast_data', 'westcoast_data', 'mountains1_data', 'mountain2_data', 'mountains2_data'])\n",
      "dict_keys(['ca_state', 'midwest_state', 'northeast_state', 'southeast_state', 'westcoast_state', 'mountains1_state', 'mountain2_state', 'mountains2_state'])\n"
     ]
    }
   ],
   "source": [
    "# Having the data imported, we now want to wrangle the data. \n",
    "# This code chunk saves each geography in its own variable and assigns key:value pairs to the dataframes for each state\n",
    "# Afterwards each state will get its own variable with all the route information from that state.\n",
    "\n",
    "\n",
    "# look at the keys generated for the two dictionary\n",
    "print(geographies_data.keys())\n",
    "\n",
    "print(geographies_states.keys())\n",
    "\n",
    "# Extract the keys from the dictionaries as variables with the list values defining those variables.\n",
    "# Save the list of keys in a list.\n",
    "\n",
    "list_of_state_names = []\n",
    "list_of_dataframes = []\n",
    "\n",
    "for key, value in geographies_data.items(): # geographies_data.items() provides a way to access and work with the individual key-value pairs of the dictionary.\n",
    "    globals()[key] = value \n",
    "    # This line dynamically creates a new variable within the loop to add to the global namespace with the name of the current key, \n",
    "    # and assigns it to the corresponding value.\n",
    "    list_of_dataframes.append(globals()[key]) # fill the list with the dataframes.\n",
    "\n",
    "for key, value in geographies_states.items():\n",
    "    globals()[key] = value\n",
    "    list_of_state_names.append(globals()[key]) \n",
    "\n",
    "# After having each region as a variable with a list of dataframes or a list of their state names,\n",
    "# we want to combine them. Each state name should become a variable for its corresponding data frame.\n",
    "# States that appear as duplicates are tracked and saved seperately.\n",
    "\n",
    "# to track the count of each state name across region and to avoid overwriting data frames of  states that already appeared in another geopgraphy,\n",
    "# we need to keep track of their counts. This helps control duplicates.\n",
    "\n",
    "state_counts = {} # initialize dictionary to track state counts. \n",
    "duplicates = {} # initialize dictionary to track duplicate states. \n",
    "list_of_all_states_and_data = {} # initialze dictionary without duplicates\n",
    "\n",
    "# Here we create a nested for loop that iterates over the lists containing the state names and dataframes.\n",
    "# Zip allows for iteration at the same time. For each item of the lists we have lists.\n",
    "# The nested for loop therefore iterates over the items of the lists lists.\n",
    "\n",
    "for states, dataframes in zip(list_of_state_names, list_of_dataframes) :\n",
    "    for state, dataframe in zip(states, dataframes) :\n",
    "        # Add state to the global namespace if it does not exist so far and set its count to 1.\n",
    "        if state not in globals():\n",
    "            globals()[state] = dataframe\n",
    "            state_counts[state] = 1\n",
    "            list_of_all_states_and_data[state] = dataframe\n",
    "        else:\n",
    "        # If state already exists, save the duplicate in a sperate variable, increase its count by 1 and add the count value to the variable name.   \n",
    "            count = state_counts.get(state, 1) + 1\n",
    "            state_counts[state] = count\n",
    "            state_i = state + \"_\" + str(count)\n",
    "            globals()[state_i] = dataframe\n",
    "            duplicates[state] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d16e3e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mi': 2, 'az': 2, 'id': 2, 'mt': 2, 'nm': 2, 'nv': 2, 'wy': 2}\n",
      "False\n",
      "183253\n",
      "Index(['route_name', 'grade', 'safety', 'type', 'fa', 'description',\n",
      "       'location', 'protection', 'metadata'],\n",
      "      dtype='object')\n",
      "209808\n",
      "Index(['route_name', 'grade', 'safety', 'type', 'fa', 'description',\n",
      "       'location', 'protection', 'metadata', 'mp_sector_id', 'mp_route_id',\n",
      "       'State'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# This code chunk compares the duplicated state dfs and joins their data frames if they are not equal without duplication.\n",
    "# If the data is equal, we ignore the second data set of that state.\n",
    "# This code chunk then adds a State column to each data frame containing the state name, \n",
    "# to later identify from which state that routes is from. \n",
    "# We then merge all state dfs into a single df.\n",
    "\n",
    "# First we check if data frames of state duplicates are identical.\n",
    "\n",
    "print(duplicates)\n",
    "\n",
    "are_equal = mi.equals(mi_2)\n",
    "\n",
    "print(are_equal)\n",
    "\n",
    "# Looking at the namespace and size (rows) of all duplicate data frames \n",
    "# It is fair to assume that all data frames in the list duplicates are actually duplicates.\n",
    "# They can therefore be ignored in our further analysis and we continue with the list of all states filled earlier.\n",
    "\n",
    "\n",
    "len(list_of_all_states_and_data) # How many states\n",
    "\n",
    "# Add the key (state) as a separate column to each DataFrame\n",
    "for state, df in list_of_all_states_and_data.items():\n",
    "    df['State'] = state\n",
    "\n",
    "# Merge all dfs of the individual states into a single df containing all routes\n",
    "df_all_states = pd.concat(list_of_all_states_and_data.values(), ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code chunk compares the two data frames, the published data frame containing all data from August 2020\n",
    "# and our generated df of all routes from all states.\n",
    "\n",
    "# Make sure there are no duplicates\n",
    "all.drop_duplicates(subset = 'route_name')\n",
    "df_all_states.drop_duplicates(subset = 'route_name')\n",
    "\n",
    "# Compare the length and the columns of the two dfs.\n",
    "print(len(all))\n",
    "print(all.columns)\n",
    "print(len(df_all_states))\n",
    "print(df_all_states.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0bfb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe4b13dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_name</th>\n",
       "      <th>grade</th>\n",
       "      <th>safety</th>\n",
       "      <th>type</th>\n",
       "      <th>fa</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>protection</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wheres Waldo?</td>\n",
       "      <td>{'YDS': 'V2', 'Font': '5+'}</td>\n",
       "      <td></td>\n",
       "      <td>{'boulder': True}</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Sit Start on the crack. Pull a big move to a ...</td>\n",
       "      <td></td>\n",
       "      <td>[Pads]</td>\n",
       "      <td>{'left_right_seq': '999999', 'parent_lnglat': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>{'tr': True, 'ice': True}</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>[Just a general entry for the routes. Usually ...</td>\n",
       "      <td>[Can't miss the silo with a giant sheet of ice...</td>\n",
       "      <td>[No gear needed. All supplied and is Top Rope]</td>\n",
       "      <td>{'left_right_seq': '0', 'parent_lnglat': [-92....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vanished Edens</td>\n",
       "      <td>{'YDS': 'V4', 'Font': '6B'}</td>\n",
       "      <td></td>\n",
       "      <td>{'boulder': True}</td>\n",
       "      <td>Joe Feldman, 2019</td>\n",
       "      <td>[Start right hand in a sidepull slot and left ...</td>\n",
       "      <td>[Hot Stuff Camp Roof]</td>\n",
       "      <td>[pad - good landing]</td>\n",
       "      <td>{'left_right_seq': '1', 'parent_lnglat': [-91....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stairway to Heaven</td>\n",
       "      <td>{'YDS': '5.7', 'French': '5a', 'Ewbanks': '15'...</td>\n",
       "      <td></td>\n",
       "      <td>{'trad': True, 'tr': True}</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Climb the large flake right of Slot Machine t...</td>\n",
       "      <td></td>\n",
       "      <td>[SR, tricams are handy.]</td>\n",
       "      <td>{'left_right_seq': '5', 'parent_lnglat': [-91....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shagadelic Humper Bumper</td>\n",
       "      <td>{'YDS': '5.8', 'French': '5b', 'Ewbanks': '16'...</td>\n",
       "      <td></td>\n",
       "      <td>{'tr': True}</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[Climb the buttress left of Cake Walk.]</td>\n",
       "      <td></td>\n",
       "      <td>[Build a TR anchor on off of trees above.]</td>\n",
       "      <td>{'left_right_seq': '999999', 'parent_lnglat': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183248</th>\n",
       "      <td>State of Delusion</td>\n",
       "      <td>{'YDS': '5.10b', 'French': '6a+', 'Ewbanks': '...</td>\n",
       "      <td></td>\n",
       "      <td>{'trad': True, 'sport': True}</td>\n",
       "      <td>Ron Cotman, Gordon Briordy</td>\n",
       "      <td>[Start on the thin seam climbers left of Halcy...</td>\n",
       "      <td>[Starts on the thin seam in between Halcyon an...</td>\n",
       "      <td>[Gear to 2\". Small nuts are great. 4 bolts]</td>\n",
       "      <td>{'left_right_seq': '2', 'parent_lnglat': [-120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183249</th>\n",
       "      <td>Pistachio Pillar</td>\n",
       "      <td>{'YDS': '5.10c', 'French': '6b', 'Ewbanks': '2...</td>\n",
       "      <td></td>\n",
       "      <td>{'sport': True}</td>\n",
       "      <td>Ron Cotman 2003</td>\n",
       "      <td>[A tricky route following the green streak up ...</td>\n",
       "      <td>[Center of The Nuthouse]</td>\n",
       "      <td>[7 bolts]</td>\n",
       "      <td>{'left_right_seq': '1', 'parent_lnglat': [-120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183250</th>\n",
       "      <td>Halcyon Daze</td>\n",
       "      <td>{'YDS': '5.11d', 'French': '7a', 'Ewbanks': '2...</td>\n",
       "      <td></td>\n",
       "      <td>{'sport': True}</td>\n",
       "      <td>Alec Gibbons, Brian Behle, 2005</td>\n",
       "      <td>[A very long sport route with multiple roof pu...</td>\n",
       "      <td>[Right where the trail comes into The Nuthouse...</td>\n",
       "      <td>[13 bolts]</td>\n",
       "      <td>{'left_right_seq': '3', 'parent_lnglat': [-120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183251</th>\n",
       "      <td>Commited</td>\n",
       "      <td>{'YDS': '5.11c', 'French': '6c+', 'Ewbanks': '...</td>\n",
       "      <td></td>\n",
       "      <td>{'trad': True}</td>\n",
       "      <td>Tony Bentley and Ron Cotman</td>\n",
       "      <td>[The obvious sweeping corner on the wall. Basi...</td>\n",
       "      <td>[Uphill from Halcyon Daze on the far left side...</td>\n",
       "      <td>[Tips to 3\"]</td>\n",
       "      <td>{'left_right_seq': '0', 'parent_lnglat': [-120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183252</th>\n",
       "      <td>420 Moderate</td>\n",
       "      <td>{'YDS': 'V2', 'Font': '5+'}</td>\n",
       "      <td></td>\n",
       "      <td>{'boulder': True}</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[This is the historically chipped line on the ...</td>\n",
       "      <td>[On the up hill side of the 420 boulder.]</td>\n",
       "      <td>[Crash pads.]</td>\n",
       "      <td>{'left_right_seq': '999999', 'parent_lnglat': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183253 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      route_name  \\\n",
       "0                  Wheres Waldo?   \n",
       "1                        Unknown   \n",
       "2                 Vanished Edens   \n",
       "3             Stairway to Heaven   \n",
       "4       Shagadelic Humper Bumper   \n",
       "...                          ...   \n",
       "183248         State of Delusion   \n",
       "183249          Pistachio Pillar   \n",
       "183250              Halcyon Daze   \n",
       "183251                  Commited   \n",
       "183252              420 Moderate   \n",
       "\n",
       "                                                    grade safety  \\\n",
       "0                             {'YDS': 'V2', 'Font': '5+'}          \n",
       "1                                                      {}          \n",
       "2                             {'YDS': 'V4', 'Font': '6B'}          \n",
       "3       {'YDS': '5.7', 'French': '5a', 'Ewbanks': '15'...          \n",
       "4       {'YDS': '5.8', 'French': '5b', 'Ewbanks': '16'...          \n",
       "...                                                   ...    ...   \n",
       "183248  {'YDS': '5.10b', 'French': '6a+', 'Ewbanks': '...          \n",
       "183249  {'YDS': '5.10c', 'French': '6b', 'Ewbanks': '2...          \n",
       "183250  {'YDS': '5.11d', 'French': '7a', 'Ewbanks': '2...          \n",
       "183251  {'YDS': '5.11c', 'French': '6c+', 'Ewbanks': '...          \n",
       "183252                        {'YDS': 'V2', 'Font': '5+'}          \n",
       "\n",
       "                                 type                               fa  \\\n",
       "0                   {'boulder': True}                          unknown   \n",
       "1           {'tr': True, 'ice': True}                           Unkown   \n",
       "2                   {'boulder': True}                Joe Feldman, 2019   \n",
       "3          {'trad': True, 'tr': True}                          unknown   \n",
       "4                        {'tr': True}                          unknown   \n",
       "...                               ...                              ...   \n",
       "183248  {'trad': True, 'sport': True}       Ron Cotman, Gordon Briordy   \n",
       "183249                {'sport': True}                  Ron Cotman 2003   \n",
       "183250                {'sport': True}  Alec Gibbons, Brian Behle, 2005   \n",
       "183251                 {'trad': True}      Tony Bentley and Ron Cotman   \n",
       "183252              {'boulder': True}                          unknown   \n",
       "\n",
       "                                              description  \\\n",
       "0       [Sit Start on the crack. Pull a big move to a ...   \n",
       "1       [Just a general entry for the routes. Usually ...   \n",
       "2       [Start right hand in a sidepull slot and left ...   \n",
       "3       [Climb the large flake right of Slot Machine t...   \n",
       "4                 [Climb the buttress left of Cake Walk.]   \n",
       "...                                                   ...   \n",
       "183248  [Start on the thin seam climbers left of Halcy...   \n",
       "183249  [A tricky route following the green streak up ...   \n",
       "183250  [A very long sport route with multiple roof pu...   \n",
       "183251  [The obvious sweeping corner on the wall. Basi...   \n",
       "183252  [This is the historically chipped line on the ...   \n",
       "\n",
       "                                                 location  \\\n",
       "0                                                           \n",
       "1       [Can't miss the silo with a giant sheet of ice...   \n",
       "2                                   [Hot Stuff Camp Roof]   \n",
       "3                                                           \n",
       "4                                                           \n",
       "...                                                   ...   \n",
       "183248  [Starts on the thin seam in between Halcyon an...   \n",
       "183249                           [Center of The Nuthouse]   \n",
       "183250  [Right where the trail comes into The Nuthouse...   \n",
       "183251  [Uphill from Halcyon Daze on the far left side...   \n",
       "183252          [On the up hill side of the 420 boulder.]   \n",
       "\n",
       "                                            protection  \\\n",
       "0                                               [Pads]   \n",
       "1       [No gear needed. All supplied and is Top Rope]   \n",
       "2                                 [pad - good landing]   \n",
       "3                             [SR, tricams are handy.]   \n",
       "4           [Build a TR anchor on off of trees above.]   \n",
       "...                                                ...   \n",
       "183248     [Gear to 2\". Small nuts are great. 4 bolts]   \n",
       "183249                                       [7 bolts]   \n",
       "183250                                      [13 bolts]   \n",
       "183251                                    [Tips to 3\"]   \n",
       "183252                                   [Crash pads.]   \n",
       "\n",
       "                                                 metadata  \n",
       "0       {'left_right_seq': '999999', 'parent_lnglat': ...  \n",
       "1       {'left_right_seq': '0', 'parent_lnglat': [-92....  \n",
       "2       {'left_right_seq': '1', 'parent_lnglat': [-91....  \n",
       "3       {'left_right_seq': '5', 'parent_lnglat': [-91....  \n",
       "4       {'left_right_seq': '999999', 'parent_lnglat': ...  \n",
       "...                                                   ...  \n",
       "183248  {'left_right_seq': '2', 'parent_lnglat': [-120...  \n",
       "183249  {'left_right_seq': '1', 'parent_lnglat': [-120...  \n",
       "183250  {'left_right_seq': '3', 'parent_lnglat': [-120...  \n",
       "183251  {'left_right_seq': '0', 'parent_lnglat': [-120...  \n",
       "183252  {'left_right_seq': '999999', 'parent_lnglat': ...  \n",
       "\n",
       "[183253 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
